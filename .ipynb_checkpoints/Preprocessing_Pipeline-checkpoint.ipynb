{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os, gc\n",
    "import math, random\n",
    "import pickle\n",
    "import datetime, time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(train_df, calendar_df, sell_prices_df):\n",
    "    sell_prices_df['id'] = sell_prices_df['item_id'].astype('str')+'_'+sell_prices_df['store_id']+'_validation'\n",
    "    d_cols = [f'd_{i}' for i in range(1,1914)]\n",
    "    \n",
    "    event_type_1 = pd.get_dummies(calendar_df.event_type_1)\n",
    "    event_type_1.columns = [f'{col}_event_type_1' for col in event_type_1.columns]\n",
    "    event_type_2 = pd.get_dummies(calendar_df.event_type_1)\n",
    "    event_type_2.columns = [f'{col}_event_type_2' for col in event_type_2.columns]\n",
    "    calendar_data = pd.concat([\n",
    "        calendar_df.drop(columns=['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2'])[['wday', 'd','month','snap_CA', 'snap_TX', 'snap_WI']],\n",
    "        event_type_1,\n",
    "        event_type_2\n",
    "    ], axis=1)\n",
    "    calendar_data = calendar_data.set_index('d').T\n",
    "    \n",
    "    \n",
    "    \n",
    "    sell_prices_data = sell_prices_df[sell_prices_df.wm_yr_wk.isin(calendar_df.wm_yr_wk.unique())]\n",
    "    sell_prices_data.reset_index(drop=True, inplace=True)\n",
    "    tmp = sell_prices_data.groupby(['id'])[['wm_yr_wk', 'sell_price']].apply(lambda x: x.set_index('wm_yr_wk')['sell_price'].to_dict()).to_dict()\n",
    "    d = calendar_df.d\n",
    "    wm_yr_wk = calendar_df.wm_yr_wk\n",
    "    price_data = {}\n",
    "    for col in tqdm(train_df.id.unique()):\n",
    "        price_data[col] = wm_yr_wk.map(tmp[col])\n",
    "    price_data = pd.DataFrame(price_data)\n",
    "    price_data.index = d\n",
    "    \n",
    "    train_df2 = train_df.copy()\n",
    "    \n",
    "    train_df = train_df.T\n",
    "    train_df.columns = train_df.loc['id', :].values\n",
    "    train_df.loc[d_cols,  :] = train_df.loc[d_cols,  :] + np.where(\n",
    "    np.isnan(\n",
    "        price_data[price_data.index.isin(d_cols)]\n",
    "    ), np.nan,0)\n",
    "    train_df = train_df.T\n",
    "    \n",
    "    return train_df, calendar_df, calendar_data, price_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(train_cols, null_check_cols, state, train_df, calendar_data, price_data):\n",
    "    data_train = train_df[['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']+train_cols]\n",
    "    \n",
    "    null = train_df[null_check_cols].isnull().sum(axis=1)\n",
    "    null = null[null==0].index\n",
    "    data_train = data_train[data_train.id.isin(null)]\n",
    "    \n",
    "    train_price = price_data.T\n",
    "    train_price= train_price[train_cols]\n",
    "    \n",
    "    train_product = data_train[data_train.state_id==state]['id'].unique()\n",
    "    len(train_product)\n",
    "    data = data_train.loc[train_product,train_cols]\n",
    "    \n",
    "    calendar_index = [\n",
    "        'wday', 'month', f'snap_{state}', 'Cultural_event_type_1', 'National_event_type_1', 'Religious_event_type_1',\n",
    "        'Sporting_event_type_1', 'Cultural_event_type_2', 'National_event_type_2', 'Religious_event_type_2', 'Sporting_event_type_2'\n",
    "    ]\n",
    "\n",
    "    calendar = calendar_data.loc[calendar_index,:]\n",
    "    event_index = [\n",
    "        'Cultural_event_type_1', 'National_event_type_1', 'Religious_event_type_1', 'Sporting_event_type_1',\n",
    "        'Cultural_event_type_2', 'National_event_type_2', 'Religious_event_type_2', 'Sporting_event_type_2'\n",
    "    ]\n",
    "    for shift in [-14, -7, 7, 14, 28, 56]:\n",
    "        tmp_calendar = calendar.loc[event_index, :]\n",
    "        tmp_calendar = tmp_calendar.T.shift(-shift).T\n",
    "        tmp_calendar.index = [f'{col}_shift{shift}' for col in tmp_calendar.index]\n",
    "        calendar = pd.concat([\n",
    "            calendar,\n",
    "            tmp_calendar\n",
    "        ], axis=0)\n",
    "    calendar = calendar[train_cols]\n",
    "    \n",
    "    price = price_data.T[train_cols].loc[train_product,:]\n",
    "    price_1 = price_data.loc[:,train_product].shift(-3).T[train_cols]\n",
    "    price_2 = price_data.loc[:,train_product].shift(-7).T[train_cols]\n",
    "    price_3 = price_data.loc[:,train_product].shift(-14).T[train_cols]\n",
    "\n",
    "    past_price_1 = price_data.loc[:,train_product].shift(3).T[train_cols]\n",
    "    past_price_2 = price_data.loc[:,train_product].shift(7).T[train_cols]\n",
    "    past_price_3 = price_data.loc[:,train_product].shift(14).T[train_cols]\n",
    "    print(\n",
    "        price_1.isnull().sum().sum(),\n",
    "        price_2.isnull().sum().sum(),\n",
    "        price_3.isnull().sum().sum())\n",
    "    print(\n",
    "        past_price_1.isnull().sum().sum(), \n",
    "        past_price_2.isnull().sum().sum(), \n",
    "        past_price_3.isnull().sum().sum()\n",
    "    )\n",
    "    \n",
    "    data = torch.FloatTensor(data.values.astype(float))\n",
    "    calendar = torch.FloatTensor(calendar.values.astype(float))\n",
    "    price = torch.FloatTensor(price.values.astype(float))\n",
    "    price_1 = torch.FloatTensor(price_1.values.astype(float))\n",
    "    price_2 = torch.FloatTensor(price_2.values.astype(float))\n",
    "    price_3= torch.FloatTensor(price_3.values.astype(float))\n",
    "    \n",
    "    past_price_1 = torch.FloatTensor(past_price_1.values.astype(float))\n",
    "    past_price_2 = torch.FloatTensor(past_price_2.values.astype(float))\n",
    "    past_price_3 = torch.FloatTensor(past_price_3.values.astype(float))\n",
    "    \n",
    "    return data, calendar, price, price_1, price_2, price_3, past_price_1, past_price_2, past_price_3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/kanoumotoharu/Downloads/m5-forecasting-accuracy/'\n",
    "#path = '/Users/abcdm/Downloads/m5-forecasting-accuracy/'\n",
    "\n",
    "original_train_df = pd.read_csv(path+'sales_train_validation.csv')\n",
    "calendar_df = pd.read_csv(path+'calendar.csv')\n",
    "sell_prices_df = pd.read_csv(path+'sell_prices.csv')\n",
    "sample_submission_df = pd.read_csv(path+'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6e17d474ca411cbe31772ef25ba55e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30490), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df, calendar_df, calendar_data, price_data = Preprocessing(original_train_df, calendar_df, sell_prices_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "d_cols = [f'd_{i}' for i in range(1,1914)]\n",
    "train_cols = d_cols[-200:]\n",
    "null_check_cols = d_cols[-214:]\n",
    "#'snap_CA', 'snap_TX', 'snap_WI'\n",
    "state='CA'\n",
    "data, calendar, price, price_1, price_2, price_3, past_price_1, past_price_2, past_price_3 = make_data(train_cols, null_check_cols, state, train_df, calendar_data, price_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([])\n",
      "tensor([])\n",
      "tensor([])\n",
      "tensor([])\n",
      "tensor([])\n",
      "tensor([])\n",
      "tensor([])\n",
      "tensor([])\n",
      "tensor([])\n"
     ]
    }
   ],
   "source": [
    "for tnsr in [data, calendar, price, price_1, price_2, price_3, past_price_1, past_price_2, past_price_3]:\n",
    "    print(tnsr[torch.isnan(tnsr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
