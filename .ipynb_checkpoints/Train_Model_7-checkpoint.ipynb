{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/kanoumotoharu/Downloads/m5-forecasting-accuracy/'\n",
    "#path = '/Users/abcdm/Downloads/m5-forecasting-accuracy/'\n",
    "#path = '../input/m5-forecasting-accuracy/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os, gc\n",
    "import termcolor\n",
    "\n",
    "import math, random\n",
    "import pickle\n",
    "import datetime, time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(train_df, calendar_df, sell_prices_df):\n",
    "    sell_prices_df['id'] = sell_prices_df['item_id'].astype('str')+'_'+sell_prices_df['store_id']+'_validation'\n",
    "    d_cols = [f'd_{i}' for i in range(1,1914)]\n",
    "    \n",
    "    event_type_1 = pd.get_dummies(calendar_df.event_type_1)\n",
    "    event_type_1.columns = [f'{col}_event_type_1' for col in event_type_1.columns]\n",
    "    event_type_2 = pd.get_dummies(calendar_df.event_type_1)\n",
    "    event_type_2.columns = [f'{col}_event_type_2' for col in event_type_2.columns]\n",
    "    calendar_data = pd.concat([\n",
    "        calendar_df.drop(columns=['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2'])[['wday', 'd','month','snap_CA', 'snap_TX', 'snap_WI']],\n",
    "        event_type_1,\n",
    "        event_type_2\n",
    "    ], axis=1)\n",
    "    calendar_data = calendar_data.set_index('d').T\n",
    "    \n",
    "    \n",
    "    \n",
    "    sell_prices_data = sell_prices_df[sell_prices_df.wm_yr_wk.isin(calendar_df.wm_yr_wk.unique())]\n",
    "    sell_prices_data.reset_index(drop=True, inplace=True)\n",
    "    tmp = sell_prices_data.groupby(['id'])[['wm_yr_wk', 'sell_price']].apply(lambda x: x.set_index('wm_yr_wk')['sell_price'].to_dict()).to_dict()\n",
    "    d = calendar_df.d\n",
    "    wm_yr_wk = calendar_df.wm_yr_wk\n",
    "    price_data = {}\n",
    "    for col in tqdm(train_df.id.unique()):\n",
    "        price_data[col] = wm_yr_wk.map(tmp[col])\n",
    "    price_data = pd.DataFrame(price_data)\n",
    "    price_data.index = d\n",
    "    \n",
    "    \n",
    "    is_sell = price_data.notnull().astype(float).T\n",
    "    price_data = price_data.fillna(0)\n",
    "    \n",
    "    train_df = train_df.T\n",
    "    train_df.columns = train_df.loc['id', :].values\n",
    "    train_df = train_df.T\n",
    "    \n",
    "    return train_df, calendar_df, calendar_data, price_data, is_sell\n",
    "\n",
    "\n",
    "def make_calendar_data(calendar_data, train_cols):\n",
    "    calendar_index = [\n",
    "        'wday', 'month',\n",
    "        'Cultural_event_type_1', 'National_event_type_1', 'Religious_event_type_1', 'Sporting_event_type_1',\n",
    "        'Cultural_event_type_2', 'National_event_type_2', 'Religious_event_type_2', 'Sporting_event_type_2'\n",
    "    ]\n",
    "    calendar = calendar_data.loc[calendar_index,:]\n",
    "    event_index = [\n",
    "        'Cultural_event_type_1', 'National_event_type_1', 'Religious_event_type_1', 'Sporting_event_type_1',\n",
    "        'Cultural_event_type_2', 'National_event_type_2', 'Religious_event_type_2', 'Sporting_event_type_2'\n",
    "    ]\n",
    "    for shift in [3, 7, 14, 28]:\n",
    "        tmp_calendar = calendar.loc[event_index, :]\n",
    "        tmp_calendar = tmp_calendar.T.shift(-shift).T\n",
    "        tmp_calendar.index = [f'{col}_shift{shift}' for col in tmp_calendar.index]\n",
    "        calendar = pd.concat([\n",
    "            calendar,\n",
    "            tmp_calendar\n",
    "        ], axis=0)\n",
    "    calendar = calendar[train_cols]\n",
    "    calendar = torch.FloatTensor(calendar.values.astype(float))\n",
    "    return calendar\n",
    "\n",
    "def make_data(train_cols, state, train_df, calendar_data, price_data, is_sell_data, sample_submission_df):\n",
    "    data_train = train_df[['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']+train_cols]\n",
    "    train_product = sample_submission_df[(sample_submission_df.id.str.contains(state))&(sample_submission_df.id.str.contains('_validation'))].id.values\n",
    "    #train_product = data_train[data_train.state_id==state]['id'].unique()\n",
    "    \n",
    "    data = data_train.loc[train_product,train_cols]\n",
    "    \n",
    "    calendar_index = [ f'snap_{state}']\n",
    "    event_index = [ f'snap_{state}']\n",
    "    calendar = calendar_data.loc[calendar_index,:]\n",
    "    for shift in [3, 7, 14, 28]:\n",
    "        tmp_calendar = calendar.loc[event_index, :]\n",
    "        tmp_calendar = tmp_calendar.T.shift(shift).T\n",
    "        tmp_calendar.index = [f'{col}_shift{shift}' for col in tmp_calendar.index]\n",
    "        calendar = pd.concat([\n",
    "            calendar,\n",
    "            tmp_calendar\n",
    "        ], axis=0)\n",
    "    calendar = calendar[train_cols]\n",
    "    \n",
    "    price = price_data.T[train_cols].loc[train_product,:]\n",
    "    past_price_1 = price_data.loc[:,train_product].shift(3).T[train_cols]\n",
    "    past_price_2 = price_data.loc[:,train_product].shift(7).T[train_cols]\n",
    "    past_price_3 = price_data.loc[:,train_product].shift(14).T[train_cols]\n",
    "    \n",
    "    \n",
    "    is_sell = is_sell_data[train_cols].loc[train_product,:]\n",
    "    past_is_sell_1 = is_sell_data.T.shift(3).T.loc[train_product, train_cols]\n",
    "    past_is_sell_2 = is_sell_data.T.shift(7).T.loc[train_product, train_cols]\n",
    "    past_is_sell_3 = is_sell_data.T.shift(14).T.loc[train_product, train_cols]\n",
    "\n",
    "    data = torch.FloatTensor(data.values.astype(float))\n",
    "    \n",
    "    calendar = torch.FloatTensor(calendar.values.astype(float))\n",
    "    \n",
    "    price = torch.FloatTensor(price.values.astype(float))\n",
    "    \n",
    "    past_price_1 = torch.FloatTensor(past_price_1.values.astype(float))\n",
    "    past_price_2 = torch.FloatTensor(past_price_2.values.astype(float))\n",
    "    past_price_3 = torch.FloatTensor(past_price_3.values.astype(float))\n",
    "    \n",
    "    is_sell = torch.FloatTensor(is_sell.values.astype(float))\n",
    "    past_is_sell_1 = torch.FloatTensor(past_is_sell_1.values.astype(float))\n",
    "    past_is_sell_2 = torch.FloatTensor(past_is_sell_2.values.astype(float))\n",
    "    past_is_sell_3 = torch.FloatTensor(past_is_sell_3.values.astype(float))\n",
    "    \n",
    "    data_list = []\n",
    "    for idx in range(len(data)):\n",
    "        _data = data[[idx],:]\n",
    "        _price = price[[idx],:]\n",
    "        \n",
    "        _past_price_1 = past_price_1[[idx],:]\n",
    "        _past_price_2 = past_price_2[[idx],:]\n",
    "        _past_price_3 = past_price_3[[idx],:]\n",
    "        \n",
    "        _is_sell = is_sell[[idx],:]\n",
    "        \n",
    "        _past_is_sell_1 = past_is_sell_1[[idx],:]\n",
    "        _past_is_sell_2 = past_is_sell_2[[idx],:]\n",
    "        _past_is_sell_3 = past_is_sell_3[[idx],:]\n",
    "        \n",
    "        x = torch.cat((\n",
    "            _data, calendar,\n",
    "            _price,\n",
    "            _past_price_1, _past_price_2, _past_price_3,\n",
    "            _is_sell,\n",
    "            _past_is_sell_1, _past_is_sell_2, _past_is_sell_3\n",
    "        ), dim=0)\n",
    "        data_list.append(x.tolist())\n",
    "    data_list = torch.FloatTensor(data_list)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mish(input):\n",
    "    return input * torch.tanh(nn.functional.softplus(input))\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return mish(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class residual_conv1d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channel):\n",
    "        super(residual_conv1d, self).__init__()\n",
    "        \n",
    "        self.mish = Mish()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv1d(in_channel, in_channel, 1),\n",
    "            Mish(),\n",
    "            nn.Conv1d(in_channel, in_channel, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x+self.layer(x)\n",
    "        x = self.mish(x)\n",
    "        return x\n",
    "\n",
    "class Conv_1d_Net(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channel):\n",
    "        super(Conv_1d_Net, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channel, 2*in_channel, 1),\n",
    "            nn.Dropout(0.2),\n",
    "            Mish(),\n",
    "            residual_conv1d(2*in_channel)\n",
    "        )\n",
    "        \n",
    "        self.layer_2 = nn.Sequential(\n",
    "            nn.Conv1d(2*in_channel, 4*in_channel, 1),\n",
    "            nn.Dropout(0.2),\n",
    "            Mish(),\n",
    "            residual_conv1d(4*in_channel)\n",
    "        )\n",
    "        \n",
    "        self.layer_3 = nn.Sequential(\n",
    "            nn.Conv1d(4*in_channel, 8*in_channel, 1),\n",
    "            nn.Dropout(0.2),\n",
    "            Mish(),\n",
    "            residual_conv1d(8*in_channel)\n",
    "        )\n",
    "       \n",
    "         \n",
    "        self.avgpool1d = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(8*in_channel, 8*in_channel),\n",
    "            nn.Dropout(0.1),\n",
    "            Mish(),\n",
    "            nn.Linear(8*in_channel, 16*in_channel),\n",
    "            nn.Dropout(0.1),\n",
    "            Mish(),\n",
    "            nn.Linear(16*in_channel, 28)\n",
    "        ) \n",
    "\n",
    "    def forward(self, x):\n",
    "        #_in = x.size()[1]\n",
    "        x = self.layer_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        #x = self.layer_4(x)\n",
    "        x = self.avgpool1d(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.optimizer import Optimizer\n",
    "import math\n",
    "\n",
    "class RAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        self.buffer = [[None, None, None] for ind in range(10)]\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = self.buffer[int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = group['lr'] / (1 - beta1 ** state['step'])\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:            \n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "                else:\n",
    "                    p_data_fp32.add_(-step_size, exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+'sales_train_validation.csv')\n",
    "calendar_df = pd.read_csv(path+'calendar.csv')\n",
    "sell_prices_df = pd.read_csv(path+'sell_prices.csv')\n",
    "sample_submission_df = pd.read_csv(path+'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a060ae28904690b8dad22bad876b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30490), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 52.7 s, sys: 5.12 s, total: 57.8 s\n",
      "Wall time: 58.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df, calendar_df, calendar_data, price_data, is_sell = Preprocessing(df, calendar_df, sell_prices_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'snap_CA', 'snap_TX', 'snap_WI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.24 ms, sys: 195 µs, total: 2.43 ms\n",
      "Wall time: 2.29 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d_cols = df.columns[df.columns.str.startswith('d_')].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = d_cols[-100:]\n",
    "\n",
    "state='CA'\n",
    "data_ca = make_data(cols, state, train_df, calendar_data, price_data, is_sell, sample_submission_df)\n",
    "state='TX'\n",
    "data_tx = make_data(cols, state, train_df, calendar_data, price_data, is_sell, sample_submission_df)\n",
    "state='WI'\n",
    "data_wi = make_data(cols, state, train_df, calendar_data, price_data, is_sell, sample_submission_df)\n",
    "\n",
    "\n",
    "data = torch.cat(\n",
    "    (data_ca, data_tx, data_wi),\n",
    "    dim=0\n",
    ")\n",
    "calendar = make_calendar_data(calendar_data, cols)\n",
    "del data_ca, data_tx, data_wi\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30490, 14, 100])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.FloatTensor([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.rand(10,100).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.cat((a,b),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 100])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[1],:,:].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class indicate_index(torch.utils.data.Dataset):\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_batch_data(index, data, calendar):\n",
    "    _data = data[index, :, :]\n",
    "    x = torch.tensor([])\n",
    "    for tmp_x in _data:\n",
    "        tmp_x = torch.cat((tmp_x, calendar),dim=0)\n",
    "        x = torch.cat((x,tmp_x.unsqueeze(0)), dim=0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_func_item_id_state_id_(nn.Module):\n",
    "    def __init__(self, df, cols, index_index):\n",
    "        super(Loss_func_item_id_state_id_, self).__init__()\n",
    "        \n",
    "        self.index_index = index_index\n",
    "        last_d = int(cols[-1].replace('d_', ''))\n",
    "        d_cols = df.columns[df.columns.str.startswith('d_')]\n",
    "        train_d_cols = last_d-28*2\n",
    "        self.train_d_cols = d_cols[:train_d_cols]\n",
    "        test_d_cols = last_d-28\n",
    "        self.test_d_cols = d_cols[:test_d_cols]\n",
    "        self._create_denominator(df)\n",
    "        \n",
    "    def _create_denominator(self, df):\n",
    "        g_df = df.groupby(['item_id', 'state_id'])#[d_cols].sum()\n",
    "        \n",
    "        train_value = g_df[self.train_d_cols].sum()\n",
    "        train_value = train_value.loc[self.index_index,:]\n",
    "        train_value = train_value.values\n",
    "        train_value = train_value[:,1:]-train_value[:,:-1]\n",
    "        train_value = train_value**2\n",
    "        train_value = train_value.mean(1)\n",
    "        train_value[train_value==0]=1\n",
    "        self.train_value = torch.FloatTensor(train_value)\n",
    "        \n",
    "        test_value = g_df[self.test_d_cols].sum()\n",
    "        test_value = test_value.loc[self.index_index,:]\n",
    "        test_value = test_value.values\n",
    "        test_value = test_value[:,1:]-test_value[:,:-1]\n",
    "        test_value = test_value**2\n",
    "        test_value = test_value.mean(1)\n",
    "        test_value[test_value==0]=1\n",
    "        self.test_value = torch.FloatTensor(test_value)\n",
    "        \n",
    "    def forward(self, preds, true, idx, length, train):\n",
    "        a1=0\n",
    "        a2=0\n",
    "        Loss=0\n",
    "        for i, _len in enumerate(length):\n",
    "            _idx = idx[i]\n",
    "            a2=a1+_len\n",
    "            _preds = preds[a1:a2].sum(0)\n",
    "            _true = true[a1:a2].sum(0)\n",
    "            loss = (_preds -_true)**2\n",
    "            loss = loss.mean()\n",
    "            loss = loss.squeeze()\n",
    "            if train:\n",
    "                loss = loss/self.train_value[_idx]\n",
    "            else:\n",
    "                loss = loss/self.test_value[_idx]\n",
    "            loss = torch.sqrt(loss)\n",
    "            Loss+=loss/len(length)\n",
    "            a1=a2\n",
    "        return Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['index'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_df = pd.concat([\n",
    "    df.groupby(['item_id', 'state_id'])['index'].unique(),\n",
    "    df.groupby(['item_id', 'state_id'])['index'].nunique()\n",
    "], axis=1)\n",
    "index_df.columns=['index', 'length']\n",
    "index_df['index'] = index_df['index'].apply(lambda x: x.tolist())\n",
    "\n",
    "index_index = index_df.index\n",
    "index_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set=indicate_index(index_df)\n",
    "data_loader = torch.utils.data.DataLoader(data_set, batch_size = 31, shuffle = True)\n",
    "for idx in data_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>[3021, 6070, 9119, 12168]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>[1701, 4750, 7799, 10848]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>[2192, 5241, 8290, 11339]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[1628, 4677, 7726, 10775]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2354</th>\n",
       "      <td>[23739, 26788, 29837]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          index  length\n",
       "4227  [3021, 6070, 9119, 12168]       4\n",
       "267   [1701, 4750, 7799, 10848]       4\n",
       "1740  [2192, 5241, 8290, 11339]       4\n",
       "48    [1628, 4677, 7726, 10775]       4\n",
       "2354      [23739, 26788, 29837]       3"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_df.iloc[idx].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 4, 4, 3]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = sum(index_df.iloc[idx]['index'].values.tolist(),[])\n",
    "length = index_df.iloc[idx]['length'].values.tolist()\n",
    "index[:5], length[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4310445785522461, tensor(0.4310, grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = _create_batch_data(index, data, calendar)\n",
    "loss_func = Loss_func_item_id_state_id_(df, d_cols[-100:], index_index)\n",
    "y = X[:,0,-28:]\n",
    "preds = y+torch.rand(y.size())*0.5\n",
    "preds.requires_grad=True\n",
    "loss = loss_func(preds, y, idx, length,train=True)\n",
    "loss.item(), loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_item_id_state_id_(model, df, cols, index_index):\n",
    "    lr = 1e-4\n",
    "    eta_min = 1e-3\n",
    "    t_max = 10\n",
    "    model = model.to(DEVICE)\n",
    "    criterion = Loss_func_item_id_state_id_(cols=cols, df=df, index_index=index_index)\n",
    "    optimizer = RAdam(params=model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n",
    "    return model, criterion, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_X_y(x_batch):\n",
    "    y_batch = x_batch[:,0,-28:]\n",
    "    x_batch = x_batch[:,:,:-28]\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_item_id_state_id_(model, data, calendar):\n",
    "    \n",
    "    \n",
    "    index_df = pd.concat([\n",
    "        df.groupby(['item_id', 'state_id'])['index'].unique(),\n",
    "        df.groupby(['item_id', 'state_id'])['index'].nunique()\n",
    "    ], axis=1)\n",
    "    index_df.columns=['index', 'length']\n",
    "    index_df['index'] = index_df['index'].apply(lambda x: x.tolist())\n",
    "\n",
    "    index_index = index_df.index\n",
    "    index_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    data_set=indicate_index(index_df)\n",
    "    data_loader = torch.utils.data.DataLoader(data_set, batch_size = 33, shuffle = True)\n",
    "    \n",
    "    model, criterion, optimizer, scheduler = prepare_training(model, df, cols, index_index)\n",
    "    \n",
    "    \n",
    "    \n",
    "    num_epochs = 40\n",
    "    best_epoch = -1\n",
    "    best_score = 10000\n",
    "    early_stoppping_cnt = 0\n",
    "    best_model = model\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        model.train()\n",
    "        avg_loss = 0.\n",
    "        \n",
    "        for idx in tqdm(data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            index = sum(index_df.iloc[idx]['index'].values.tolist(),[])\n",
    "            length = index_df.iloc[idx]['length'].values.tolist()\n",
    "            x_batch = _create_batch_data(index, data, calendar)\n",
    "            x_batch = x_batch[:,:,:-28]; gc.collect()\n",
    "            \n",
    "            x_batch, y_batch = split_X_y(x_batch)\n",
    "            x_batch = x_batch.to(DEVICE)\n",
    "            y_batch = y_batch.to(DEVICE)\n",
    "            \n",
    "            preds = model(x_batch)\n",
    "            \n",
    "            loss = criterion(preds.cpu(), y_batch.cpu(), idx, length, train=True)\n",
    "            loss = loss.to(DEVICE)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            avg_loss += loss.item() / len(data_loader)\n",
    "            del loss; gc.collect()\n",
    "        \n",
    "        model.eval()\n",
    "        avg_val_loss = 0.\n",
    "        \n",
    "        for idx in data_loader:\n",
    "             x_batch = _create_batch_data(index, data, calendar)\n",
    "            \n",
    "            x_batch, y_batch = split_X_y(x_batch)\n",
    "            x_batch = x_batch.to(DEVICE)\n",
    "            y_batch = y_batch.to(DEVICE)\n",
    "            \n",
    "            preds = model(x_batch)\n",
    "            loss = criterion(preds.cpu(), y_batch.cpu(), idx, length, train=False)\n",
    "            \n",
    "            avg_val_loss += loss.item() / len(data_loader)\n",
    "            del loss; gc.collect()\n",
    "            \n",
    "            \n",
    "        if best_score>avg_val_loss:\n",
    "            best_score = avg_val_loss\n",
    "            early_stoppping_cnt=0\n",
    "            best_epoch=epoch\n",
    "            best_model = model\n",
    "            elapsed = time.time() - start_time\n",
    "            p_avg_val_loss = termcolor.colored(np.round(avg_val_loss, 4),\"red\")\n",
    "            \n",
    "            print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {p_avg_val_loss} time: {elapsed:.0f}s')\n",
    "        else:\n",
    "            early_stoppping_cnt+=1\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f} time: {elapsed:.0f}s')\n",
    "        \n",
    "        if (epoch>10) and (early_stoppping_cnt>7):\n",
    "                break\n",
    "    \n",
    "    print(f'best_score : {best_score}    best_epoch : {best_epoch}')\n",
    "    #torch.save(best_score.state_dict(), 'net.pt')\n",
    "    \n",
    "    return best_model, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_size=56\n",
    "model = Conv_1d_Net(in_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5758"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d7304bbf9d4489be77ccd9a69fe6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=204.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 - avg_train_loss: 147.1387  avg_val_loss: \u001b[31m139.2076\u001b[0m time: 69s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95811ca8af5d440ab1597740901cd12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=204.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 - avg_train_loss: 132.2557  avg_val_loss: 139.2566 time: 71s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad471201a50d4ff9b090fbd1e1147de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=204.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-39e2b44e8f96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model_item_id_store_id_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#loader = train_model_item_id_store_id_(model, data_set)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-126-ead3a85b6756>\u001b[0m in \u001b[0;36mtrain_model_item_id_store_id_\u001b[1;34m(model, data_set)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[1;32mdel\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model, best_score = train_model_item_id_store_id_(model, data_set)\n",
    "#loader = train_model_item_id_store_id_(model, data_set)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = best_model(X[:,:,:-28].to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0915, grad_fn=<SqrtBackward>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(l(out.cpu(),X[:,0,-28:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X[:,0,-28:].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.276524</td>\n",
       "      <td>1.112931</td>\n",
       "      <td>1.247054</td>\n",
       "      <td>1.327819</td>\n",
       "      <td>1.303352</td>\n",
       "      <td>1.698812</td>\n",
       "      <td>1.960324</td>\n",
       "      <td>1.250759</td>\n",
       "      <td>1.213059</td>\n",
       "      <td>1.250396</td>\n",
       "      <td>...</td>\n",
       "      <td>1.157655</td>\n",
       "      <td>1.365267</td>\n",
       "      <td>1.410547</td>\n",
       "      <td>1.138887</td>\n",
       "      <td>1.010535</td>\n",
       "      <td>1.076578</td>\n",
       "      <td>1.025220</td>\n",
       "      <td>1.273729</td>\n",
       "      <td>1.514358</td>\n",
       "      <td>1.297700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.008877</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>-0.031807</td>\n",
       "      <td>-0.035249</td>\n",
       "      <td>-0.024112</td>\n",
       "      <td>-0.011888</td>\n",
       "      <td>-0.011735</td>\n",
       "      <td>-0.019340</td>\n",
       "      <td>-0.005448</td>\n",
       "      <td>-0.009074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038978</td>\n",
       "      <td>-0.041588</td>\n",
       "      <td>-0.030442</td>\n",
       "      <td>-0.001468</td>\n",
       "      <td>-0.014567</td>\n",
       "      <td>-0.018331</td>\n",
       "      <td>-0.004540</td>\n",
       "      <td>-0.037685</td>\n",
       "      <td>-0.031696</td>\n",
       "      <td>0.003182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.080448</td>\n",
       "      <td>0.093266</td>\n",
       "      <td>0.059631</td>\n",
       "      <td>0.060443</td>\n",
       "      <td>0.066811</td>\n",
       "      <td>0.097842</td>\n",
       "      <td>0.120918</td>\n",
       "      <td>0.073330</td>\n",
       "      <td>0.080813</td>\n",
       "      <td>0.075127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047664</td>\n",
       "      <td>0.062549</td>\n",
       "      <td>0.075112</td>\n",
       "      <td>0.075925</td>\n",
       "      <td>0.062116</td>\n",
       "      <td>0.063845</td>\n",
       "      <td>0.075785</td>\n",
       "      <td>0.059319</td>\n",
       "      <td>0.088768</td>\n",
       "      <td>0.103606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.395085</td>\n",
       "      <td>0.368079</td>\n",
       "      <td>0.381124</td>\n",
       "      <td>0.398706</td>\n",
       "      <td>0.393694</td>\n",
       "      <td>0.505883</td>\n",
       "      <td>0.598538</td>\n",
       "      <td>0.388345</td>\n",
       "      <td>0.376763</td>\n",
       "      <td>0.382284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346098</td>\n",
       "      <td>0.419548</td>\n",
       "      <td>0.439125</td>\n",
       "      <td>0.355694</td>\n",
       "      <td>0.323647</td>\n",
       "      <td>0.342387</td>\n",
       "      <td>0.341748</td>\n",
       "      <td>0.390486</td>\n",
       "      <td>0.484859</td>\n",
       "      <td>0.428769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.189064</td>\n",
       "      <td>0.188698</td>\n",
       "      <td>0.172063</td>\n",
       "      <td>0.176787</td>\n",
       "      <td>0.179414</td>\n",
       "      <td>0.236837</td>\n",
       "      <td>0.284901</td>\n",
       "      <td>0.183146</td>\n",
       "      <td>0.184114</td>\n",
       "      <td>0.181187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151765</td>\n",
       "      <td>0.187212</td>\n",
       "      <td>0.199431</td>\n",
       "      <td>0.172455</td>\n",
       "      <td>0.153453</td>\n",
       "      <td>0.163384</td>\n",
       "      <td>0.171023</td>\n",
       "      <td>0.175853</td>\n",
       "      <td>0.230200</td>\n",
       "      <td>0.218982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.155826</td>\n",
       "      <td>0.157009</td>\n",
       "      <td>0.139816</td>\n",
       "      <td>0.144037</td>\n",
       "      <td>0.147181</td>\n",
       "      <td>0.194730</td>\n",
       "      <td>0.234194</td>\n",
       "      <td>0.149902</td>\n",
       "      <td>0.151413</td>\n",
       "      <td>0.149055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123672</td>\n",
       "      <td>0.153037</td>\n",
       "      <td>0.164429</td>\n",
       "      <td>0.142981</td>\n",
       "      <td>0.126997</td>\n",
       "      <td>0.134916</td>\n",
       "      <td>0.141937</td>\n",
       "      <td>0.145075</td>\n",
       "      <td>0.190068</td>\n",
       "      <td>0.182565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.913504</td>\n",
       "      <td>0.807299</td>\n",
       "      <td>0.903410</td>\n",
       "      <td>0.969485</td>\n",
       "      <td>0.940913</td>\n",
       "      <td>1.206974</td>\n",
       "      <td>1.399123</td>\n",
       "      <td>0.901995</td>\n",
       "      <td>0.857336</td>\n",
       "      <td>0.893168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840016</td>\n",
       "      <td>0.998348</td>\n",
       "      <td>1.052995</td>\n",
       "      <td>0.817338</td>\n",
       "      <td>0.744259</td>\n",
       "      <td>0.775291</td>\n",
       "      <td>0.747358</td>\n",
       "      <td>0.928336</td>\n",
       "      <td>1.098920</td>\n",
       "      <td>0.934090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.116039</td>\n",
       "      <td>0.125780</td>\n",
       "      <td>0.096333</td>\n",
       "      <td>0.098541</td>\n",
       "      <td>0.103465</td>\n",
       "      <td>0.143277</td>\n",
       "      <td>0.174963</td>\n",
       "      <td>0.109423</td>\n",
       "      <td>0.114874</td>\n",
       "      <td>0.110261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080897</td>\n",
       "      <td>0.102978</td>\n",
       "      <td>0.116506</td>\n",
       "      <td>0.107606</td>\n",
       "      <td>0.092183</td>\n",
       "      <td>0.096108</td>\n",
       "      <td>0.107620</td>\n",
       "      <td>0.096658</td>\n",
       "      <td>0.134726</td>\n",
       "      <td>0.142035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>3.835128</td>\n",
       "      <td>3.241328</td>\n",
       "      <td>3.824639</td>\n",
       "      <td>4.123936</td>\n",
       "      <td>3.965327</td>\n",
       "      <td>5.189938</td>\n",
       "      <td>5.700460</td>\n",
       "      <td>3.743864</td>\n",
       "      <td>3.713140</td>\n",
       "      <td>3.797074</td>\n",
       "      <td>...</td>\n",
       "      <td>3.584643</td>\n",
       "      <td>4.166892</td>\n",
       "      <td>4.326209</td>\n",
       "      <td>3.317772</td>\n",
       "      <td>3.041123</td>\n",
       "      <td>3.306641</td>\n",
       "      <td>3.179044</td>\n",
       "      <td>4.037484</td>\n",
       "      <td>4.743622</td>\n",
       "      <td>4.037775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2.893340</td>\n",
       "      <td>2.457325</td>\n",
       "      <td>2.816018</td>\n",
       "      <td>3.047950</td>\n",
       "      <td>2.943056</td>\n",
       "      <td>3.904403</td>\n",
       "      <td>4.347696</td>\n",
       "      <td>2.796585</td>\n",
       "      <td>2.762705</td>\n",
       "      <td>2.849051</td>\n",
       "      <td>...</td>\n",
       "      <td>2.628747</td>\n",
       "      <td>3.070882</td>\n",
       "      <td>3.219682</td>\n",
       "      <td>2.520088</td>\n",
       "      <td>2.249560</td>\n",
       "      <td>2.419385</td>\n",
       "      <td>2.302677</td>\n",
       "      <td>2.918294</td>\n",
       "      <td>3.417890</td>\n",
       "      <td>2.949725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    1.276524  1.112931  1.247054  1.327819  1.303352  1.698812  1.960324   \n",
       "1   -0.008877  0.011669 -0.031807 -0.035249 -0.024112 -0.011888 -0.011735   \n",
       "2    0.080448  0.093266  0.059631  0.060443  0.066811  0.097842  0.120918   \n",
       "3    0.395085  0.368079  0.381124  0.398706  0.393694  0.505883  0.598538   \n",
       "4    0.189064  0.188698  0.172063  0.176787  0.179414  0.236837  0.284901   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "195  0.155826  0.157009  0.139816  0.144037  0.147181  0.194730  0.234194   \n",
       "196  0.913504  0.807299  0.903410  0.969485  0.940913  1.206974  1.399123   \n",
       "197  0.116039  0.125780  0.096333  0.098541  0.103465  0.143277  0.174963   \n",
       "198  3.835128  3.241328  3.824639  4.123936  3.965327  5.189938  5.700460   \n",
       "199  2.893340  2.457325  2.816018  3.047950  2.943056  3.904403  4.347696   \n",
       "\n",
       "           7         8         9   ...        18        19        20  \\\n",
       "0    1.250759  1.213059  1.250396  ...  1.157655  1.365267  1.410547   \n",
       "1   -0.019340 -0.005448 -0.009074  ... -0.038978 -0.041588 -0.030442   \n",
       "2    0.073330  0.080813  0.075127  ...  0.047664  0.062549  0.075112   \n",
       "3    0.388345  0.376763  0.382284  ...  0.346098  0.419548  0.439125   \n",
       "4    0.183146  0.184114  0.181187  ...  0.151765  0.187212  0.199431   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "195  0.149902  0.151413  0.149055  ...  0.123672  0.153037  0.164429   \n",
       "196  0.901995  0.857336  0.893168  ...  0.840016  0.998348  1.052995   \n",
       "197  0.109423  0.114874  0.110261  ...  0.080897  0.102978  0.116506   \n",
       "198  3.743864  3.713140  3.797074  ...  3.584643  4.166892  4.326209   \n",
       "199  2.796585  2.762705  2.849051  ...  2.628747  3.070882  3.219682   \n",
       "\n",
       "           21        22        23        24        25        26        27  \n",
       "0    1.138887  1.010535  1.076578  1.025220  1.273729  1.514358  1.297700  \n",
       "1   -0.001468 -0.014567 -0.018331 -0.004540 -0.037685 -0.031696  0.003182  \n",
       "2    0.075925  0.062116  0.063845  0.075785  0.059319  0.088768  0.103606  \n",
       "3    0.355694  0.323647  0.342387  0.341748  0.390486  0.484859  0.428769  \n",
       "4    0.172455  0.153453  0.163384  0.171023  0.175853  0.230200  0.218982  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "195  0.142981  0.126997  0.134916  0.141937  0.145075  0.190068  0.182565  \n",
       "196  0.817338  0.744259  0.775291  0.747358  0.928336  1.098920  0.934090  \n",
       "197  0.107606  0.092183  0.096108  0.107620  0.096658  0.134726  0.142035  \n",
       "198  3.317772  3.041123  3.306641  3.179044  4.037484  4.743622  4.037775  \n",
       "199  2.520088  2.249560  2.419385  2.302677  2.918294  3.417890  2.949725  \n",
       "\n",
       "[200 rows x 28 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2    3     4    5     6     7     8     9   ...    18    19  \\\n",
       "0    1.0   2.0   1.0  0.0   1.0  1.0   1.0   0.0   3.0   1.0  ...   0.0   0.0   \n",
       "1    0.0   0.0   0.0  0.0   0.0  0.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   \n",
       "2    0.0   0.0   0.0  0.0   0.0  1.0   0.0   0.0   0.0   0.0  ...   0.0   0.0   \n",
       "3    0.0   0.0   1.0  1.0   0.0  1.0   0.0   0.0   0.0   0.0  ...   1.0   2.0   \n",
       "4    0.0   0.0   2.0  0.0   1.0  0.0   0.0   0.0   0.0   0.0  ...   0.0   1.0   \n",
       "..   ...   ...   ...  ...   ...  ...   ...   ...   ...   ...  ...   ...   ...   \n",
       "195  0.0   0.0   0.0  0.0   0.0  1.0   0.0   0.0   0.0   0.0  ...   0.0   1.0   \n",
       "196  0.0   2.0   0.0  1.0   0.0  0.0   0.0   1.0   1.0   1.0  ...   0.0   1.0   \n",
       "197  1.0   0.0   0.0  1.0   0.0  0.0   1.0   0.0   0.0   0.0  ...   0.0   0.0   \n",
       "198  6.0  10.0  11.0  8.0  12.0  8.0  26.0  11.0  15.0  13.0  ...  11.0  11.0   \n",
       "199  0.0   0.0   7.0  2.0   5.0  3.0   2.0   5.0   2.0   1.0  ...   1.0   4.0   \n",
       "\n",
       "       20    21   22    23   24   25   26   27  \n",
       "0     0.0   2.0  2.0   1.0  1.0  1.0  0.0  0.0  \n",
       "1     0.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  \n",
       "2     0.0   0.0  0.0   0.0  0.0  1.0  0.0  0.0  \n",
       "3     0.0   0.0  0.0   0.0  0.0  1.0  0.0  0.0  \n",
       "4     1.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  \n",
       "..    ...   ...  ...   ...  ...  ...  ...  ...  \n",
       "195   0.0   0.0  0.0   0.0  1.0  0.0  0.0  0.0  \n",
       "196   1.0   1.0  2.0   1.0  0.0  0.0  0.0  1.0  \n",
       "197   1.0   0.0  0.0   0.0  0.0  0.0  0.0  0.0  \n",
       "198  22.0  12.0  9.0  10.0  6.0  7.0  8.0  6.0  \n",
       "199   6.0   2.0  4.0   4.0  4.0  5.0  4.0  5.0  \n",
       "\n",
       "[200 rows x 28 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
